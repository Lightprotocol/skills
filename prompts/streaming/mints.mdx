<Prompt description="Stream light-mint accounts and metadata via Laserstream gRPC" actions={["copy", "cursor"]}>
{`---
description: Stream light-mint accounts and metadata via Laserstream gRPC
allowed-tools: Bash, Read, Write, Edit, Glob, Grep, WebFetch, AskUserQuestion, Task, TaskCreate, TaskGet, TaskList, TaskUpdate, TaskOutput, mcp__deepwiki, mcp__zkcompression
---

## Stream light-mint accounts and metadata via Laserstream gRPC

Context:
- Guide: https://zkcompression.com/light-token/toolkits/for-streaming-mints
- Skills and resources index: https://zkcompression.com/skill.md
- Dedicated skill: https://github.com/Lightprotocol/skills/tree/main/skills/data-streaming
- Crates: helius-laserstream, light-token-interface, borsh, futures
- Token accounts streaming: https://zkcompression.com/light-token/toolkits/for-streaming-tokens

Key APIs: LaserstreamConfig, subscribe(), Mint::deserialize(), ExtensionStruct::TokenMetadata

### 1. Index project
- Grep \`helius_laserstream|laserstream|subscribe|StreamExt|light_token_interface|Mint|cTokenmWW8bLPjZEBAUgYy3zKxQZW6VKi7bqNFEVv3m\` across src/
- Glob \`**/*.rs\` and \`**/Cargo.toml\` for project structure
- Identify: existing gRPC streaming setup, account caching, deserialization logic
- Read Cargo.toml — note existing dependencies
- Task subagent (Grep/Read/WebFetch) if project has multiple crates to scan in parallel

### 2. Read references
- WebFetch the guide above — follow the Steps (Connect, Subscribe, Deserialize, Detect cold, Extract metadata)
- WebFetch skill.md — check for a dedicated skill and resources matching this task
- TaskCreate one todo per phase below to track progress

### 3. Clarify intention
- AskUserQuestion: what is the goal? (new streaming pipeline for mints, add mint streaming to existing token streaming, specific use case like metadata indexing)
- AskUserQuestion: mainnet or devnet?
- AskUserQuestion: do you need cold/hot transition detection, or just live mint state?
- Summarize findings and wait for user confirmation before implementing

### 4. Create plan
- Based on steps 1–3, draft an implementation plan
- Follow the guide's step order: Connect → Subscribe (account + transaction subs) → Deserialize Mint → Detect Cold → Extract Metadata
- If anything is unclear or ambiguous, loop back to step 3 (AskUserQuestion)
- Present the plan to the user for approval before proceeding

### 5. Implement
- Add deps if missing: Bash \`cargo add helius-laserstream@0.1 light-token-interface@0.3 borsh@0.10 futures@0.3 bs58@0.5 tokio --features full\`
- Follow the guide and the approved plan
- Write/Edit to create or modify files
- TaskUpdate to mark each step done

### 6. Verify
- Bash \`cargo check\`
- Bash \`cargo test\` if tests exist
- TaskUpdate to mark complete

### Tools
- mcp__zkcompression__SearchLightProtocol("<query>") for API details
- mcp__deepwiki__ask_question("Lightprotocol/light-protocol", "<q>") for architecture
- Task subagent with Grep/Read/WebFetch for parallel lookups
- TaskList to check remaining work`}
</Prompt>

```text
---
description: Stream light-mint accounts and metadata via Laserstream gRPC
allowed-tools: Bash, Read, Write, Edit, Glob, Grep, WebFetch, AskUserQuestion, Task, TaskCreate, TaskGet, TaskList, TaskUpdate, TaskOutput, mcp__deepwiki, mcp__zkcompression
---

## Stream light-mint accounts and metadata via Laserstream gRPC

Context:
- Guide: https://zkcompression.com/light-token/toolkits/for-streaming-mints
- Skills and resources index: https://zkcompression.com/skill.md
- Dedicated skill: https://github.com/Lightprotocol/skills/tree/main/skills/data-streaming
- Crates: helius-laserstream, light-token-interface, borsh, futures
- Token accounts streaming: https://zkcompression.com/light-token/toolkits/for-streaming-tokens

Key APIs: LaserstreamConfig, subscribe(), Mint::deserialize(), ExtensionStruct::TokenMetadata

### 1. Index project
- Grep `helius_laserstream|laserstream|subscribe|StreamExt|light_token_interface|Mint|cTokenmWW8bLPjZEBAUgYy3zKxQZW6VKi7bqNFEVv3m` across src/
- Glob `**/*.rs` and `**/Cargo.toml` for project structure
- Identify: existing gRPC streaming setup, account caching, deserialization logic
- Read Cargo.toml — note existing dependencies
- Task subagent (Grep/Read/WebFetch) if project has multiple crates to scan in parallel

### 2. Read references
- WebFetch the guide above — follow the Steps (Connect, Subscribe, Deserialize, Detect cold, Extract metadata)
- WebFetch skill.md — check for a dedicated skill and resources matching this task
- TaskCreate one todo per phase below to track progress

### 3. Clarify intention
- AskUserQuestion: what is the goal? (new streaming pipeline for mints, add mint streaming to existing token streaming, specific use case like metadata indexing)
- AskUserQuestion: mainnet or devnet?
- AskUserQuestion: do you need cold/hot transition detection, or just live mint state?
- Summarize findings and wait for user confirmation before implementing

### 4. Create plan
- Based on steps 1–3, draft an implementation plan
- Follow the guide's step order: Connect → Subscribe (account + transaction subs) → Deserialize Mint → Detect Cold → Extract Metadata
- If anything is unclear or ambiguous, loop back to step 3 (AskUserQuestion)
- Present the plan to the user for approval before proceeding

### 5. Implement
- Add deps if missing: Bash `cargo add helius-laserstream@0.1 light-token-interface@0.3 borsh@0.10 futures@0.3 bs58@0.5 tokio --features full`
- Follow the guide and the approved plan
- Write/Edit to create or modify files
- TaskUpdate to mark each step done

### 6. Verify
- Bash `cargo check`
- Bash `cargo test` if tests exist
- TaskUpdate to mark complete

### Tools
- mcp__zkcompression__SearchLightProtocol("<query>") for API details
- mcp__deepwiki__ask_question("Lightprotocol/light-protocol", "<q>") for architecture
- Task subagent with Grep/Read/WebFetch for parallel lookups
- TaskList to check remaining work
```
